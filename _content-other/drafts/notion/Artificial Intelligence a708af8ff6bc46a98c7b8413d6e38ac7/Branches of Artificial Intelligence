# Branches of Artificial Intelligence

## **Machine Learning**

Machine Learning (ML) is a subfield of artificial intelligence (AI) that focuses on the development of algorithms and models that enable computers to learn and make predictions or decisions without explicit programming.

In other words, ML algorithms use patterns and statistical techniques to analyze, understand, and derive insights from data to improve their performance on a specific task over time.

**There are three main types of machine learning:**

1. Supervised Learning
2. Unsupervised Learning
3. Reinforcement Learning

**Supervised Learning**

In supervised learning, the algorithm is trained on a labeled dataset, which means that each data point in the training set has an associated output or label.

The goal is for the algorithm to learn a mapping from inputs to outputs so it can make accurate predictions on new, unseen data.

**A simplified example of a dataset:**

| ID | Age | Gender | Occupation | Salary |
| --- | --- | --- | --- | --- |
| 001 | 35 | Male | Engineer | $85,000 |
| 002 | 24 | Female | Teacher | $50,000 |
| 003 | 42 | Male | Doctor | $150,000 |
| 004 | 31 | Female | Lawyer | $100,000 |
| ... | ... | ... | .... | ... |
| 100 | 31 | Female | Lawyer | ? |

Looking at this dummy example above, we would provide a series of independent variables (data points) and the machine would find patterns & relationships, then (after training) we run that 100th item and see if the machine can predict the "Salary" field.

Of course this is a very simplified example, but it illustrates the general idea of how supervised learning works.

The data points you provide are called indepedent variables.

The data points that the AI looks to predict are called dependent variables.

Examples of supervised learning tasks include classification (e.g., spam detection) and regression (e.g., predicting house prices).

**Unsupervised Learning**

The goal of an unsupervised learning algorithm would be to identify any patterns or relationships in the data on its own, without any guidance from labeled examples. In this case, the algorithm might try to group the data points into clusters based on similarities or differences in their features.

Note that in unsupervised learning, there is no "correct" answer or labeled output for the algorithm to compare its predictions to. Instead, the goal is to find interesting patterns or structures in the data that can help us understand it better.

**Here is an example of an unsupervised learning dummy data set:**

| ID | Age | Income | Education Level | Homeownership |
| --- | --- | --- | --- | --- |
| 001 | 28 | $50,000 | Bachelor's Degree | Renting |
| 002 | 42 | $75,000 | Master's Degree | Own |
| 003 | 35 | $60,000 | High School Diploma | Own |
| 004 | 48 | $90,000 | Doctorate Degree | Own |
| 005 | 23 | $40,000 | Associate's Degree | Renting |
| 006 | 31 | $65,000 | Bachelor's Degree | Renting |
| 007 | 39 | $80,000 | Master's Degree | Own |
| 008 | 27 | $45,000 | High School Diploma | Renting |

This dataset contains information about eight individuals, with features such as Age, Income, Education Level, and Homeownership.

Exploratory analysis of this dataset might reveal relationships between these different features. For example, we might observe that individuals with higher levels of education tend to have higher incomes and are more likely to own their homes.

We could also investigate whether there is a relationship between age and homeownership, or between income and education level.

These relationships can help us better understand the factors that influence homeownership and income, and inform policy decisions and business strategies.

**Unsupervised Learning Task Examples**

**Here are just a few examples of some uses for unsupervised learning:**

1. **Anomaly detection**: Identifying unusual patterns or outliers in a dataset that do not conform to the normal behavior of the data. This can be useful in detecting fraud or identifying defects in manufacturing processes.
2. **Association rule mining**: Discovering interesting relationships or patterns between variables in a dataset, such as frequent itemsets or rules that indicate the co-occurrence of certain items or events.
3. **Density estimation**: Estimating the probability density function of a dataset, which can be useful in modeling and generating new data samples from the same distribution.
4. **Neural network autoencoders**: Using neural networks to learn a compressed representation of a dataset, which can be used for tasks such as image or text generation, or for pre-training models for downstream tasks.
5. **Generative adversarial networks (GANs)**: Using two neural networks, one to generate synthetic data and another to discriminate between real and fake data, to learn a generative model that can generate new samples from the same distribution as the original dataset.

**Reinforcement Learning**

Reinforcement learning is a type of machine learning that allows computers to learn and make decisions through trial and error, similar to how humans and animals learn through feedback from the environment.

In reinforcement learning, a computer program, called an agent, interacts with its environment and receives feedback in the form of rewards or punishments. The agent learns to take actions that maximize the rewards it receives and minimize the punishments.

**Teach a dog to sit**

For example, imagine teaching a dog to sit.

- When the dog sits, it receives a treat as a reward.
- If it does not sit, it does not receive a treat.

Over time, the dog learns to associate sitting with receiving a reward, and it will sit on command to receive a treat.

In reinforcement learning, the computer program works in a similar way.

The agent takes actions in an environment and receives a reward or punishment based on the outcome of the action.

The goal of the agent is to learn a policy, or a set of rules for taking actions, that maximizes the total reward it receives over time.

By learning from experience and feedback, reinforcement learning algorithms can improve their decision-making abilities and achieve better performance over time.

Reinforcement learning has many practical applications, such as in robotics, game playing, and optimization problems.

**Reinforcement Learning Example: StarCraft**

First, wtf is StarCraft?

Hint: It's fuckin awesome.

*StarCraft is a popular real-time strategy video game developed and published by Blizzard Entertainment. The game was first released in 1998 and has since become one of the most successful and influential games in the genre.*

*In StarCraft, players control armies of units and engage in battles with other players or computer-controlled opponents. The game is set in a science-fiction universe and features three distinct factions, each with its own unique units, buildings, and strategies.*

*The gameplay of StarCraft involves resource management, base building, and strategic combat. Players must gather resources such as minerals and gas to construct buildings, train units, and research upgrades. They must also defend their own bases and launch attacks against their opponents, using a variety of tactics and strategies to outmaneuver and outsmart their opponents.*

*The game has a large and active competitive scene, with professional players and teams competing in tournaments for cash prizes and prestige. StarCraft has also had a significant impact on the development of the esports industry, with many of the conventions and structures of modern esports competitions being influenced by the game.*

**AI vs. Human**

*[In 2019, researchers at Google DeepMind used reinforcement learning to develop an AI system called AlphaStar that could play StarCraft II at a professional level.](https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii)*

AlphaStar learned to play the game by interacting with the environment, taking actions such as moving units, constructing buildings, and attacking opponents. It received feedback in the form of a reward or punishment based on the outcome of its actions, such as winning or losing battles, gaining or losing resources, or constructing new buildings.

Through trial and error, AlphaStar learned to take actions that maximized its chances of winning the game. It learned strategies such as scouting the opponent's base, expanding its own base, and building a balanced army. Over time, AlphaStar's performance improved, and it was able to beat professional human players in a series of matches.

Even more impressively, this is with restrictions placed on AlphaStar's ability to select and click things in the game to ensure a fair match against human players.

Specifically, the AI system was limited to 22 "camera actions" per minute, which is the same number of clicks per minute that a human player can make using a standard keyboard and mouse setup.

This was done to ensure that AlphaStar's abilities were comparable to those of a human player, and to prevent the AI system from having an unfair advantage. The idea was to create a level playing field for the matches, while still allowing AlphaStar to demonstrate its ability to learn complex strategies and tactics through reinforcement learning.

**Result:**

- AlphaStar: 5 wins
- Humans: 1 win

# **Deep Learning**

- Definition and explanation of Deep Learning (DL)
- Neural Networks and their architecture
    - Convolutional Neural Networks (CNNs)
    - Recurrent Neural Networks (RNNs)
    - Long Short-Term Memory (LSTM) networks
    - Generative Adversarial Networks (GANs)
- Applications of DL in various industries
    - Computer vision, natural language processing, speech recognition, etc.Deep Learning (DL) is a subset of machine learning, which in turn is a subset of artificial intelligence (AI). It involves the use of neural networks to model complex patterns and representations in data. These neural networks are designed to automatically learn and improve from experience without being explicitly programmed. Deep learning has gained popularity due to its ability to process large amounts of data, identify patterns, and make predictions with high accuracy.

Neural Networks are the foundation of deep learning. They are inspired by the structure and function of the human brain, consisting of interconnected nodes or neurons that process and transmit information. The architecture of a neural network consists of multiple layers: an input layer, one or more hidden layers, and an output layer. Each layer contains a number of neurons that are connected through weighted connections called synapses.

There are several types of neural network architectures:

1. Convolutional Neural Networks (CNNs): These networks are specifically designed for processing grid-like data such as images. They consist of convolutional layers that apply filters to local regions in the input data, pooling layers that reduce spatial dimensions, and fully connected layers that perform classification tasks.
2. Recurrent Neural Networks (RNNs): These networks are designed for processing sequential data such as time series or natural language text. RNNs have connections that loop back on themselves, allowing them to maintain an internal state or memory over time.
3. Long Short-Term Memory (LSTM) networks: LSTMs are a type of RNN specifically designed to address the vanishing gradient problem in training deep recurrent networks by introducing special gating mechanisms within each neuron.
4. Generative Adversarial Networks (GANs): These consist of two neural networks – a generator and a discriminator – that work together in a competitive framework. The generator creates fake samples while the discriminator tries to distinguish between real and fake samples. This process helps both networks improve their performance over time.

Deep Learning has found applications in various industries:

1. Computer Vision: DL techniques like CNNs are used for image classification, object detection, and segmentation, enabling applications such as facial recognition, autonomous vehicles, and medical imaging analysis.
2. Natural Language Processing (NLP): DL techniques like RNNs and LSTMs are used for tasks such as sentiment analysis, machine translation, and text summarization.
3. Speech Recognition: DL models are employed to convert spoken language into written text, enabling voice assistants like Siri or Alexa to understand human speech.
4. Healthcare: Deep learning is used in drug discovery, disease diagnosis based on medical imaging data, and predicting patient outcomes.
5. Finance: DL is applied in fraud detection, credit scoring, algorithmic trading, and customer segmentation.
6. Gaming: Deep learning models have been successful in mastering complex games like Go and chess by training on large datasets of gameplays.
7. Robotics: DL is used in robotic systems for tasks such as navigation, manipulation, and decision-making based on sensor inputs.

In summary, deep learning is a powerful machine learning technique that leverages neural networks to learn complex patterns in data automatically. With various architectures like CNNs, RNNs, LSTMs, and GANs available for different types of data and tasks, deep learning has found widespread applications across numerous industries.

# **Natural Language Processing**

- Definition and explanation of Natural Language Processing (NLP)
- Key concepts in NLP: Tokenization, Lemmatization, Sentiment Analysis, etc.
- Techniques used in NLP: Rule-based systems, Statistical methods, Machine learning-based approaches
- Applications of NLP in various industries:
    - Chatbots, sentiment analysis tools, machine translation systems

# **Expert Systems**

- Definition and explanation of Expert Systems (ES)
- Components of an ES: Knowledge Base, Inference Engine, User Interface
- Advantages and limitations of ES compared to human experts
- Applications of ES in various industries:
    - Medical diagnosis systems, financial planning tools

# **Robotics**

- Definition and explanation of Robotics
- Link between AI & Robotics
- Types: Autonomous robots vs. remote-controlled robots
- Components: Sensors & Actuators
- Robot Locomotion: Wheeled Robots vs. Legged Robots
- Applications of Robotics in various industries:
- Manufacturing, Healthcare, Agriculture, Space exploration

# **Computer Vision**

- Definition and explanation of Computer Vision (CV)
- Techniques used in CV: Image processing, Feature extraction, Object recognition
- Applications of CV in various industries:
- Facial recognition systems, autonomous vehicles, surveillance systems

# **Speech Recognition**

- Definition and explanation of Speech Recognition (SR)
- Techniques used in SR: Hidden Markov Models (HMMs), Deep Learning-based approaches
- Applications of SR in various industries:
- Voice assistants (Siri, Alexa), transcription services

# **Conclusion**

- Recap of the branches of AI covered in the article
- The future potential and challenges for AI